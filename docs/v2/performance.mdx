---
title: "Performance Tuning"
description: "Optimizing isol8 for low latency and high throughput."
icon: "gauge-high"
---

isol8 is designed for speed, but the right configuration can make it even faster. This guide covers pool strategies, resource sizing, and concurrency.

## Pool Strategies

The container pool is the primary mechanism for reducing cold-start latency. You can choose between two strategies depending on your security/performance trade-off.

### Fast Strategy (Default)

The `fast` strategy prioritizes speed by maintaining a "clean" pool that is instantly ready.

- **Behavior**:
    1.  Containers are acquired from the clean pool (O(1) operation).
    2.  After use, they are moved to a "dirty" pool.
    3.  A background task cleans dirty containers (killing processes, wiping files) and returns them to the clean pool.
    4.  If the clean pool is empty, it falls back to synchronous cleaning or creation.
- **Latency**: ~125ms (mostly runtime startup overhead).
- **Best For**: High-throughput applications, chatbots, agents where 50-100ms matters.

### Secure Strategy

The `secure` strategy prioritizes isolation guarantees by cleaning *before* reuse.

- **Behavior**:
    1.  Containers are pulled from the pool.
    2.  They are cleaned synchronously *inside* the `acquire()` call.
    3.  After use, they are returned to the pool (dirty).
- **Latency**: ~200-250ms (includes cleaning overhead on critical path).
- **Best For**: Paranoid security environments where background cleanup race conditions (however unlikely) are unacceptable.

### Configuration

Configure via CLI or `isol8.config.json`:

```bash
# CLI
isol8 run script.py --pool-strategy fast --pool-size "2,2"
```

```json
// isol8.config.json
{
  // 2 clean containers ready, 2 allowed to be dirty
  "poolSize": { "clean": 2, "dirty": 2 },
  "poolStrategy": "fast"
}
```

## Pool Sizing

The `poolSize` determines how many containers are kept warm.

- **Too Small**: You'll exhaust the pool during bursts, forcing slow cold starts.
- **Too Large**: You waste system memory (each container takes ~10-50MB RAM even when idle).

**Recommendation**: Set `clean` pool size to your expected average concurrency. If you expect 5 simultaneous users, set `poolSize: { clean: 5, dirty: 5 }`.

## Concurrency Limits

The `maxConcurrent` setting (global semaphore) puts a hard cap on parallel executions to protect your host.

- **Default**: 10.
- **Behavior**: Requests exceeding the limit are queued.
- **Queueing**: If your pool is large but `maxConcurrent` is small, you won't utilize the pool fully. Ensure `maxConcurrent >= poolSize.clean`.

## Resource Limits

Tight resource limits can impact startup time.

- **CPU**: Python/Node runtimes need CPU during startup to load interpreters. Giving them < 0.5 CPUs can significantly increase cold-start time.
- **Memory**: Ensure `memoryLimit` is high enough for your runtime + workload. OOM kills are expensive to recover from.

## Pre-baking Images

Installing packages at runtime (`--install`) adds massive overhead (seconds to minutes). **Always** use custom images for production.

1.  Identify common packages (numpy, pandas, lodash).
2.  Run `isol8 setup --python numpy,pandas`.
3.  Enjoy sub-150ms starts with pre-installed dependencies.
